# OpenAI Agent SDK Integration

–ü–æ—à–∞–≥–æ–≤–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ file-knowledge-mcp —Å OpenAI Agent SDK.

## –û–±–∑–æ—Ä

OpenAI Agent SDK –Ω–µ –∏–º–µ–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ MCP, –ø–æ—ç—Ç–æ–º—É —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Å–ª–æ–π –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è. –°—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞:

1. **–ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ MCP –∫–ª–∏–µ–Ω—Ç** (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) - Python –∫–ª–∏–µ–Ω—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç MCP —Å–µ—Ä–≤–µ—Ä –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –µ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤ OpenAI function calling
2. **REST API wrapper** - –°–æ–∑–¥–∞—Ç—å HTTP API –ø–æ–≤–µ—Ä—Ö MCP —Å–µ—Ä–≤–µ—Ä–∞

---

## –ü–æ–¥—Ö–æ–¥ 1: –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç OpenAI Agent SDK –Ω–∞–ø—Ä—è–º—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã MCP —Å–µ—Ä–≤–µ—Ä–∞.

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ MCP —Å–µ—Ä–≤–µ—Ä
pip install file-knowledge-mcp

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ MCP –∫–ª–∏–µ–Ω—Ç—Å–∫—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É
pip install mcp

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OpenAI SDK
pip install openai

# –°–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
# Ubuntu/Debian:
sudo apt install ugrep poppler-utils

# macOS:
brew install ugrep poppler
```

### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ MCP-OpenAI Bridge

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `mcp_openai_bridge.py`:

```python
import asyncio
import json
from typing import Any, Dict, List
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI


class MCPOpenAIBridge:
    """–ú–æ—Å—Ç –º–µ–∂–¥—É MCP —Å–µ—Ä–≤–µ—Ä–æ–º –∏ OpenAI Agent SDK."""

    def __init__(self, knowledge_root: str, openai_api_key: str):
        self.knowledge_root = knowledge_root
        self.openai_client = OpenAI(api_key=openai_api_key)
        self.mcp_session = None
        self.mcp_tools = []

    async def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç MCP —Å–µ—Ä–≤–µ—Ä –∏ –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
        server_params = StdioServerParameters(
            command="file-knowledge-mcp",
            args=["--root", self.knowledge_root]
        )

        # –ó–∞–ø—É—Å–∫–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä
        self.read, self.write = await stdio_client(server_params).__aenter__()
        self.mcp_session = await ClientSession(self.read, self.write).__aenter__()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é
        await self.mcp_session.initialize()

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        tools_list = await self.mcp_session.list_tools()
        self.mcp_tools = [tool for tool in tools_list]

        print(f"MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω. –î–æ—Å—Ç—É–ø–Ω–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {len(self.mcp_tools)}")

    async def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç MCP —Å–µ—Ä–≤–µ—Ä."""
        if self.mcp_session:
            await self.mcp_session.__aexit__(None, None, None)
        if hasattr(self, 'read'):
            await self.read.__aexit__(None, None, None)

    def get_openai_tools(self) -> List[Dict[str, Any]]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI function calling.

        Returns:
            –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        """
        openai_tools = []

        for tool in self.mcp_tools:
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.inputSchema
                }
            }
            openai_tools.append(openai_tool)

        return openai_tools

    async def call_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Any:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.

        Args:
            tool_name: –ò–º—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            arguments: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        """
        result = await self.mcp_session.call_tool(tool_name, arguments=arguments)
        return result

    async def chat(self, messages: List[Dict[str, str]], model: str = "gpt-4"):
        """
        –ß–∞—Ç —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–∑–æ–≤–æ–º MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.

        Args:
            messages: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
            model: –ú–æ–¥–µ–ª—å OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

        Returns:
            –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        tools = self.get_openai_tools()

        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
        response = self.openai_client.chat.completions.create(
            model=model,
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )

        response_message = response.choices[0].message
        tool_calls = response_message.tool_calls

        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —Ö–æ—á–µ—Ç –≤—ã–∑–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        if tool_calls:
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
            messages.append(response_message)

            # –í—ã–∑—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)

                print(f"–í—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞: {function_name} —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏: {function_args}")

                # –í—ã–∑—ã–≤–∞–µ–º MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
                function_response = await self.call_mcp_tool(
                    function_name,
                    function_args
                )

                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": json.dumps(function_response)
                })

            # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
            second_response = self.openai_client.chat.completions.create(
                model=model,
                messages=messages
            )

            return second_response.choices[0].message

        return response_message


async def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."""

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ—Å—Ç
    bridge = MCPOpenAIBridge(
        knowledge_root="./documents",  # –ü—É—Ç—å –∫ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
        openai_api_key="your-openai-api-key"  # –í–∞—à API –∫–ª—é—á OpenAI
    )

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä
        await bridge.start()

        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ª–æ–≥
        messages = [
            {
                "role": "user",
                "content": "–ù–∞–π–¥–∏ –≤ –º–æ–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"
            }
        ]

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–∑–æ–≤–æ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        response = await bridge.chat(messages, model="gpt-4")

        print(f"\n–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {response.content}")

    finally:
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä
        await bridge.stop()


if __name__ == "__main__":
    asyncio.run(main())
```

### –®–∞–≥ 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–°–æ–∑–¥–∞–π—Ç–µ `config.yaml` –¥–ª—è MCP —Å–µ—Ä–≤–µ—Ä–∞:

```yaml
knowledge:
  root: "./documents"  # –ü—É—Ç—å –∫ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º

search:
  context_lines: 5
  max_results: 50
  timeout_seconds: 30

security:
  enable_shell_filters: true
  filter_mode: whitelist
  allow_symlinks: false

exclude:
  patterns:
    - ".git/*"
    - "*.bak"
    - "*.tmp"
```

### –®–∞–≥ 4: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –≤–∞—à–µ–º –±–æ—Ç–µ

```python
import asyncio
import os
from mcp_openai_bridge import MCPOpenAIBridge


async def run_knowledge_bot():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –ª–æ–∫–∞–ª—å–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º."""

    # –°–æ–∑–¥–∞–µ–º –º–æ—Å—Ç
    bridge = MCPOpenAIBridge(
        knowledge_root="/path/to/your/documents",
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä
        await bridge.start()

        print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:")
        for tool in bridge.mcp_tools:
            print(f"  - {tool.name}: {tool.description}")

        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        while True:
            user_input = input("\n–í—ã: ")
            if user_input.lower() in ["exit", "quit", "–≤—ã—Ö–æ–¥"]:
                break

            messages = [{"role": "user", "content": user_input}]
            response = await bridge.chat(messages, model="gpt-4")

            print(f"–ë–æ—Ç: {response.content}")

    finally:
        await bridge.stop()


if __name__ == "__main__":
    asyncio.run(run_knowledge_bot())
```

### –®–∞–≥ 5: –ó–∞–ø—É—Å–∫

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å API –∫–ª—é—á–æ–º
export OPENAI_API_KEY=your-openai-api-key

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞
python your_bot.py
```

---

## –ü–æ–¥—Ö–æ–¥ 2: REST API Wrapper

–ï—Å–ª–∏ –≤–∞–º –Ω—É–∂–µ–Ω HTTP –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –¥—Ä—É–≥–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏.

### –®–∞–≥ 1: –°–æ–∑–¥–∞–Ω–∏–µ REST API

–°–æ–∑–¥–∞–π—Ç–µ `mcp_rest_server.py`:

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
import asyncio
from typing import Optional, Dict, Any
from contextlib import asynccontextmanager


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è MCP —Å–µ—Å—Å–∏–∏
mcp_session = None
mcp_read = None
mcp_write = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    global mcp_session, mcp_read, mcp_write

    # –ó–∞–ø—É—Å–∫ MCP —Å–µ—Ä–≤–µ—Ä–∞
    server_params = StdioServerParameters(
        command="file-knowledge-mcp",
        args=["--root", "./documents"]
    )

    mcp_read, mcp_write = await stdio_client(server_params).__aenter__()
    mcp_session = await ClientSession(mcp_read, mcp_write).__aenter__()
    await mcp_session.initialize()

    print("MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω")

    yield

    # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ MCP —Å–µ—Ä–≤–µ—Ä–∞
    if mcp_session:
        await mcp_session.__aexit__(None, None, None)
    if mcp_read:
        await mcp_read.__aexit__(None, None, None)

    print("MCP —Å–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


app = FastAPI(title="File Knowledge MCP REST API", lifespan=lifespan)


class SearchRequest(BaseModel):
    query: str
    collection: Optional[str] = None
    document: Optional[str] = None
    max_results: int = 20


class ReadRequest(BaseModel):
    path: str
    start_page: Optional[int] = None
    end_page: Optional[int] = None


@app.get("/")
async def root():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± API."""
    return {
        "name": "File Knowledge MCP REST API",
        "version": "1.0.0",
        "endpoints": [
            "/search - –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º",
            "/collections - –°–ø–∏—Å–æ–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–π",
            "/read - –ß—Ç–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            "/tools - –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"
        ]
    }


@app.get("/tools")
async def list_tools():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
    tools = await mcp_session.list_tools()
    return {
        "tools": [
            {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.inputSchema
            }
            for tool in tools
        ]
    }


@app.post("/search")
async def search(request: SearchRequest):
    """–ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º."""
    scope = {"type": "global"}

    if request.document:
        scope = {"type": "document", "path": request.document}
    elif request.collection:
        scope = {"type": "collection", "path": request.collection}

    try:
        result = await mcp_session.call_tool(
            "search_documents",
            arguments={
                "query": request.query,
                "scope": scope,
                "max_results": request.max_results
            }
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/collections")
async def list_collections(path: str = ""):
    """–°–ø–∏—Å–æ–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–π (–ø–∞–ø–æ–∫)."""
    try:
        result = await mcp_session.call_tool(
            "list_collections",
            arguments={"path": path}
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/read")
async def read_document(request: ReadRequest):
    """–ß—Ç–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    try:
        args = {"path": request.path}
        if request.start_page is not None:
            args["start_page"] = request.start_page
        if request.end_page is not None:
            args["end_page"] = request.end_page

        result = await mcp_session.call_tool(
            "read_document",
            arguments=args
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install fastapi uvicorn file-knowledge-mcp mcp
```

### –®–∞–≥ 3: –ó–∞–ø—É—Å–∫ REST —Å–µ—Ä–≤–µ—Ä–∞

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä
python mcp_rest_server.py

# –°–µ—Ä–≤–µ—Ä –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ http://localhost:8000
```

### –®–∞–≥ 4: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ OpenAI Agent

```python
import openai
import requests
import json


def search_knowledge(query: str, collection: str = None) -> str:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ REST API."""
    response = requests.post(
        "http://localhost:8000/search",
        json={
            "query": query,
            "collection": collection,
            "max_results": 10
        }
    )
    return json.dumps(response.json())


def read_document(path: str) -> str:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ REST API."""
    response = requests.post(
        "http://localhost:8000/read",
        json={"path": path}
    )
    return json.dumps(response.json())


# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è OpenAI
tools = [
    {
        "type": "function",
        "function": {
            "name": "search_knowledge",
            "description": "–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
                    },
                    "collection": {
                        "type": "string",
                        "description": "–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–∏—Å–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_document",
            "description": "–ü—Ä–æ—á–∏—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "–ü—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É"
                    }
                },
                "required": ["path"]
            }
        }
    }
]

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤ —á–∞—Ç–µ
client = openai.OpenAI()

messages = [
    {"role": "user", "content": "–ù–∞–π–¥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± API –≤ –º–æ–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"}
]

response = client.chat.completions.create(
    model="gpt-4",
    messages=messages,
    tools=tools,
    tool_choice="auto"
)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π
if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:
        if tool_call.function.name == "search_knowledge":
            args = json.loads(tool_call.function.arguments)
            result = search_knowledge(**args)
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞: {result}")
```

---

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤

| –ö—Ä–∏—Ç–µ—Ä–∏–π | –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è | REST API |
|----------|-------------------|----------|
| –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å | ‚ö° –ë—ã—Å—Ç—Ä–µ–µ (–Ω–µ—Ç HTTP overhead) | üêå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ (HTTP –∑–∞–ø—Ä–æ—Å—ã) |
| –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è | ‚úÖ –û–¥–∏–Ω –ø—Ä–æ—Ü–µ—Å—Å | ‚ùå –î–≤–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ (API + –±–æ—Ç) |
| –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å | ‚ùå –û–¥–∏–Ω –±–æ—Ç | ‚úÖ –ú–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤ |
| –û—Ç–ª–∞–¥–∫–∞ | ‚ùå –°–ª–æ–∂–Ω–µ–µ | ‚úÖ –ü—Ä–æ—â–µ (–º–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å curl) |
| –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å | ‚ùå –¢–æ–ª—å–∫–æ Python | ‚úÖ –õ—é–±–æ–π —è–∑—ã–∫ |

---

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **–ü—Ä—è–º—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é** - –ø—Ä–æ—â–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ, –º–µ–Ω—å—à–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.

### –î–ª—è production –∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–æ—Ç–æ–≤
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **REST API** - –ø—Ä–æ—â–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å.

---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### Docker compose –¥–ª—è production

```yaml
version: "3.8"

services:
  mcp-rest-api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./documents:/knowledge:ro
    environment:
      - FKM_KNOWLEDGE__ROOT=/knowledge
      - FKM_SECURITY__FILTER_MODE=whitelist
    restart: unless-stopped

  openai-bot:
    build: ./bot
    depends_on:
      - mcp-rest-api
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MCP_API_URL=http://mcp-rest-api:8000
    restart: unless-stopped
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import logging

# –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# –í –≤–∞—à–µ–º –±–æ—Ç–µ
logger.info(f"MCP tool called: {tool_name}")
logger.info(f"Search query: {query}")
```

---

## –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### MCP —Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É
which file-knowledge-mcp

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
which ugrep
which pdftotext
```

### Timeout –æ—à–∏–±–∫–∏
–£–≤–µ–ª–∏—á—å—Ç–µ —Ç–∞–π–º–∞—É—Ç—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
```yaml
search:
  timeout_seconds: 60

security:
  filter_timeout: 45
```

### Permission denied
```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è —á—Ç–µ–Ω–∏—è
chmod -R +r /path/to/documents
```

---

## –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [MCP Documentation](https://modelcontextprotocol.io/)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [file-knowledge-mcp Configuration](configuration.md)
- [file-knowledge-mcp Tools Reference](tools.md)
